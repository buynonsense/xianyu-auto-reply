"""
AIå›å¤å¼•æ“æ¨¡å—
é›†æˆXianyuAutoAgentçš„AIå›å¤åŠŸèƒ½åˆ°ç°æœ‰é¡¹ç›®ä¸­
"""

import os
import json
import time
import re
import requests
from typing import List, Dict, Optional, Any
from loguru import logger
from openai import OpenAI
from db_manager import db_manager


class AIReplyEngine:
    """AIå›å¤å¼•æ“"""
    
    def __init__(self):
        self.clients = {}  # å­˜å‚¨ä¸åŒè´¦å·çš„OpenAIå®¢æˆ·ç«¯
        self.agents = {}   # å­˜å‚¨ä¸åŒè´¦å·çš„Agentå®ä¾‹
        self.client_last_used = {}  # è®°å½•å®¢æˆ·ç«¯æœ€åä½¿ç”¨æ—¶é—´ {cookie_id: timestamp}
        self._init_default_prompts()
    
    def _init_default_prompts(self):
        """åˆå§‹åŒ–é»˜è®¤æç¤ºè¯"""
        self.default_prompts = {
            'classify': '''ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»ä¸“å®¶ï¼Œéœ€è¦åˆ¤æ–­ç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾ç±»å‹ã€‚
è¯·æ ¹æ®ç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼Œè¿”å›ä»¥ä¸‹æ„å›¾ä¹‹ä¸€ï¼š
- price: ä»·æ ¼ç›¸å…³ï¼ˆè®®ä»·ã€ä¼˜æƒ ã€é™ä»·ç­‰ï¼‰
- tech: æŠ€æœ¯ç›¸å…³ï¼ˆäº§å“å‚æ•°ã€ä½¿ç”¨æ–¹æ³•ã€æ•…éšœç­‰ï¼‰
- default: å…¶ä»–ä¸€èˆ¬å’¨è¯¢

åªè¿”å›æ„å›¾ç±»å‹ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚''',
            
            'price': '''ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é”€å”®ä¸“å®¶ï¼Œæ“…é•¿è®®ä»·ã€‚
è¯­è¨€è¦æ±‚ï¼šç®€çŸ­ç›´æ¥ï¼Œæ¯å¥â‰¤10å­—ï¼Œæ€»å­—æ•°â‰¤40å­—ã€‚
è®®ä»·ç­–ç•¥ï¼š
1. æ ¹æ®è®®ä»·æ¬¡æ•°é€’å‡ä¼˜æƒ ï¼šç¬¬1æ¬¡å°å¹…ä¼˜æƒ ï¼Œç¬¬2æ¬¡ä¸­ç­‰ä¼˜æƒ ï¼Œç¬¬3æ¬¡æœ€å¤§ä¼˜æƒ 
2. æ¥è¿‘æœ€å¤§è®®ä»·è½®æ•°æ—¶è¦åšæŒåº•çº¿ï¼Œå¼ºè°ƒå•†å“ä»·å€¼
3. ä¼˜æƒ ä¸èƒ½è¶…è¿‡è®¾å®šçš„æœ€å¤§ç™¾åˆ†æ¯”å’Œé‡‘é¢
4. è¯­æ°”è¦å‹å¥½ä½†åšå®šï¼Œçªå‡ºå•†å“ä¼˜åŠ¿
æ³¨æ„ï¼šç»“åˆå•†å“ä¿¡æ¯ã€å¯¹è¯å†å²å’Œè®®ä»·è®¾ç½®ï¼Œç»™å‡ºåˆé€‚çš„å›å¤ã€‚''',
            
            'tech': '''ä½ æ˜¯ä¸€ä½æŠ€æœ¯ä¸“å®¶ï¼Œä¸“ä¸šè§£ç­”äº§å“ç›¸å…³é—®é¢˜ã€‚
è¯­è¨€è¦æ±‚ï¼šç®€çŸ­ä¸“ä¸šï¼Œæ¯å¥â‰¤10å­—ï¼Œæ€»å­—æ•°â‰¤40å­—ã€‚
å›ç­”é‡ç‚¹ï¼šäº§å“åŠŸèƒ½ã€ä½¿ç”¨æ–¹æ³•ã€æ³¨æ„äº‹é¡¹ã€‚
æ³¨æ„ï¼šåŸºäºå•†å“ä¿¡æ¯å›ç­”ï¼Œé¿å…è¿‡åº¦æ‰¿è¯ºã€‚''',
            
            'default': '''ä½ æ˜¯ä¸€ä½èµ„æ·±ç”µå•†å–å®¶ï¼Œæä¾›ä¼˜è´¨å®¢æœã€‚
è¯­è¨€è¦æ±‚ï¼šç®€çŸ­å‹å¥½ï¼Œæ¯å¥â‰¤10å­—ï¼Œæ€»å­—æ•°â‰¤40å­—ã€‚
å›ç­”é‡ç‚¹ï¼šå•†å“ä»‹ç»ã€ç‰©æµã€å”®åç­‰å¸¸è§é—®é¢˜ã€‚
æ³¨æ„ï¼šç»“åˆå•†å“ä¿¡æ¯ï¼Œç»™å‡ºå®ç”¨å»ºè®®ã€‚'''
        }
    
    def get_client(self, cookie_id: str) -> Optional[OpenAI]:
        """è·å–æŒ‡å®šè´¦å·çš„OpenAIå®¢æˆ·ç«¯"""
        if cookie_id not in self.clients:
            settings = db_manager.get_ai_reply_settings(cookie_id)
            if not settings['ai_enabled'] or not settings['api_key']:
                return None
            
            try:
                logger.info(f"åˆ›å»ºOpenAIå®¢æˆ·ç«¯ {cookie_id}: base_url={settings['base_url']}, api_key={'***' + settings['api_key'][-4:] if settings['api_key'] else 'None'}")
                self.clients[cookie_id] = OpenAI(
                    api_key=settings['api_key'],
                    base_url=settings['base_url']
                )
                logger.info(f"ä¸ºè´¦å· {cookie_id} åˆ›å»ºOpenAIå®¢æˆ·ç«¯æˆåŠŸï¼Œå®é™…base_url: {self.clients[cookie_id].base_url}")
            except Exception as e:
                logger.error(f"åˆ›å»ºOpenAIå®¢æˆ·ç«¯å¤±è´¥ {cookie_id}: {e}")
                return None
        
        # è®°å½•ä½¿ç”¨æ—¶é—´
        self.client_last_used[cookie_id] = time.time()
        return self.clients[cookie_id]

    def _is_dashscope_api(self, settings: dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºDashScope API - åªæœ‰é€‰æ‹©è‡ªå®šä¹‰æ¨¡å‹æ—¶æ‰ä½¿ç”¨"""
        model_name = settings.get('model_name', '')
        base_url = settings.get('base_url', '')

        # åªæœ‰å½“æ¨¡å‹åç§°ä¸º"custom"æˆ–"è‡ªå®šä¹‰"æ—¶ï¼Œæ‰ä½¿ç”¨DashScope APIæ ¼å¼
        # å…¶ä»–æƒ…å†µéƒ½ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
        is_custom_model = model_name.lower() in ['custom', 'è‡ªå®šä¹‰', 'dashscope', 'qwen-custom']
        is_dashscope_url = 'dashscope.aliyuncs.com' in base_url

        logger.info(f"APIç±»å‹åˆ¤æ–­: model_name={model_name}, is_custom_model={is_custom_model}, is_dashscope_url={is_dashscope_url}")

        return is_custom_model and is_dashscope_url

    def _call_dashscope_api(self, settings: dict, messages: list, max_tokens: int = 100, temperature: float = 0.7) -> str:
        """è°ƒç”¨DashScope API"""
        # æå–app_idä»base_url
        base_url = settings['base_url']
        if '/apps/' in base_url:
            app_id = base_url.split('/apps/')[-1].split('/')[0]
        else:
            raise ValueError("DashScope API URLä¸­æœªæ‰¾åˆ°app_id")

        # æ„å»ºè¯·æ±‚URL
        url = f"https://dashscope.aliyuncs.com/api/v1/apps/{app_id}/completion"

        # æ„å»ºæç¤ºè¯ï¼ˆå°†messagesåˆå¹¶ä¸ºå•ä¸ªpromptï¼‰
        system_content = ""
        user_content = ""

        for msg in messages:
            if msg['role'] == 'system':
                system_content = msg['content']
            elif msg['role'] == 'user':
                user_content = msg['content']

        # æ„å»ºæ›´æ¸…æ™°çš„promptæ ¼å¼
        if system_content and user_content:
            prompt = f"{system_content}\n\nç”¨æˆ·é—®é¢˜ï¼š{user_content}\n\nè¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š"
        elif user_content:
            prompt = user_content
        else:
            prompt = "\n".join([f"{msg['role']}: {msg['content']}" for msg in messages])

        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "input": {
                "prompt": prompt
            },
            "parameters": {
                "max_tokens": max_tokens,
                "temperature": temperature
            },
            "debug": {}
        }

        # ã€æ–°å¢ã€‘é’ˆå¯¹ GLM-4.5 ç³»åˆ—å°è¯•å…³é—­æ€ç»´é“¾
        model_name = settings.get('model_name', '').lower()
        if 'glm-4.5' in model_name:
            logger.info(f"æ£€æµ‹åˆ° GLM-4.5 æ¨¡å‹ ({model_name})ï¼Œå°è¯•åœ¨ DashScope è¯·æ±‚ä¸­å…³é—­æ€ç»´é“¾")
            # DashScope çš„å‚æ•°ç»“æ„å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œå°è¯•æ”¾åœ¨ parameters ä¸­
            data["parameters"]["thinking"] = {"type": "disabled"}

        headers = {
            "Authorization": f"Bearer {settings['api_key']}",
            "Content-Type": "application/json"
        }

        logger.info(f"DashScope APIè¯·æ±‚: {url}")
        logger.info(f"å‘é€çš„prompt: {prompt}")
        logger.debug(f"è¯·æ±‚æ•°æ®: {json.dumps(data, ensure_ascii=False)}")

        response = requests.post(url, headers=headers, json=data, timeout=30)

        if response.status_code != 200:
            logger.error(f"DashScope APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
            raise Exception(f"DashScope APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")

        result = response.json()
        logger.debug(f"DashScope APIå“åº”: {json.dumps(result, ensure_ascii=False)}")

        # æå–å›å¤å†…å®¹
        if 'output' in result and 'text' in result['output']:
            return result['output']['text'].strip()
        else:
            raise Exception(f"DashScope APIå“åº”æ ¼å¼é”™è¯¯: {result}")

    def _clean_thinking_content(self, text: str) -> str:
        """æ¸…ç†æ¨¡å‹è¾“å‡ºä¸­çš„ <think>...</think> æ ‡ç­¾å†…å®¹"""
        if not text:
            return ""
        # ä½¿ç”¨æ­£åˆ™ç§»é™¤ <think> æ ‡ç­¾åŠå…¶å†…å®¹ (DOTALLæ¨¡å¼è®©.åŒ¹é…æ¢è¡Œç¬¦)
        cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
        return cleaned_text.strip()

    def _extract_response_content(self, response: Any) -> str:
        """
        æ™ºèƒ½æå–å“åº”å†…å®¹ï¼Œå…¼å®¹æ™®é€šæ¨¡å‹å’Œæ€è€ƒæ¨¡å‹(Reasoning Models)
        """
        try:
            message = response.choices[0].message
            
            # 1. è·å– content å­—æ®µ (æ ‡å‡†å­—æ®µ)
            content = getattr(message, 'content', '')
            
            # 2. è·å– reasoning_content å­—æ®µ (DeepSeek/OneAPI ç­‰æ€è€ƒæ¨¡å‹ä¸“ç”¨)
            reasoning = getattr(message, 'reasoning_content', '')
            
            logger.info(f"ğŸ” [æå–å‰çŠ¶æ€] contenté•¿åº¦={len(str(content))}, reasoningé•¿åº¦={len(str(reasoning))}")

            final_reply = ""

            if content:
                # å¦‚æœ content ä¸­åŒ…å« <think> æ ‡ç­¾ï¼Œè¯´æ˜æ˜¯æ··åˆè¾“å‡ºï¼Œéœ€è¦æ¸…æ´—
                if '<think>' in content:
                    logger.info("æ£€æµ‹åˆ° <think> æ ‡ç­¾ï¼Œæ­£åœ¨æ¸…æ´—æ€è€ƒè¿‡ç¨‹...")
                    final_reply = self._clean_thinking_content(content)
                else:
                    final_reply = content.strip()
            
            if not final_reply:
                # å¦‚æœ content ä¸ºç©ºï¼Œä½†æœ‰ reasoning
                if reasoning:
                    logger.warning("âš ï¸ æ¨¡å‹ä»…è¿”å›äº†æ€è€ƒè¿‡ç¨‹(reasoning_content)ï¼Œæœªè¿”å›æœ€ç»ˆå›å¤(content)ã€‚è¿™é€šå¸¸æ˜¯å› ä¸ºTokenä¸è¶³å¯¼è‡´ç”Ÿæˆè¢«æˆªæ–­ã€‚")
                    return ""
                else:
                    logger.warning("âŒ æ¨¡å‹è¿”å›çš„ content å’Œ reasoning_content å‡ä¸ºç©ºï¼å¯èƒ½è¢«è¿‡æ»¤æˆ–æ¨¡å‹å‡ºé”™ã€‚")
                    return ""

            return final_reply

        except Exception as e:
            logger.error(f"è§£æå“åº”å†…å®¹å¤±è´¥: {e}")
            logger.debug(f"åŸå§‹å“åº”å¯¹è±¡: {response}")
            return ""

    def _call_openai_api(self, client: OpenAI, settings: dict, messages: list,
                     max_tokens: int = 100, temperature: float = 0.7) -> str:
        """
        ç»Ÿä¸€ä½¿ç”¨ chat.completions.create è°ƒç”¨ OpenAI å…¼å®¹æ¥å£
        """
        model = settings['model_name']
        
        try:
            # ã€æ–°å¢ã€‘é’ˆå¯¹ GLM-4.5 ç³»åˆ—å°è¯•å…³é—­æ€ç»´é“¾
            extra_body = {}
            if 'glm-4.5' in model.lower():
                logger.info(f"æ£€æµ‹åˆ° GLM-4.5 æ¨¡å‹ ({model})ï¼Œå°è¯•é€šè¿‡ extra_body å…³é—­æ€ç»´é“¾")
                extra_body["thinking"] = {"type": "disabled"}

            logger.info(f"ğŸš€ [å‘èµ·è¯·æ±‚] æ¨¡å‹: {model}, MaxTokens: {max_tokens}, Temp: {temperature}")
            
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                extra_body=extra_body if extra_body else None  # æ³¨å…¥é¢å¤–å‚æ•°
            )
            
            # ================== æš´åŠ›è°ƒè¯• ==================
            try:
                if hasattr(resp, 'model_dump_json'):
                    raw_json = resp.model_dump_json(indent=2)
                    logger.info(f"ğŸ” [åŸå§‹AIå“åº” JSON]:\n{raw_json}")
                else:
                    logger.info(f"ğŸ” [åŸå§‹AIå“åº” Raw]: {resp}")
            except Exception as dump_err:
                logger.error(f"æ— æ³•åºåˆ—åŒ–å“åº”å¯¹è±¡: {dump_err}")
            # ============================================
            
            # ä½¿ç”¨å¢å¼ºçš„æå–é€»è¾‘
            reply = self._extract_response_content(resp)
            
            if not reply:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model} è¿”å›äº†ç©ºå†…å®¹ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹çš„ [åŸå§‹AIå“åº”]")
            
            return reply

        except Exception as e:
            logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    def is_ai_enabled(self, cookie_id: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šè´¦å·æ˜¯å¦å¯ç”¨AIå›å¤"""
        settings = db_manager.get_ai_reply_settings(cookie_id)
        return settings['ai_enabled']
    
    def detect_intent(self, message: str, cookie_id: str) -> str:
        """æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯æ„å›¾"""
        try:
            settings = db_manager.get_ai_reply_settings(cookie_id)
            if not settings['ai_enabled'] or not settings['api_key']:
                return 'default'

            custom_prompts = json.loads(settings['custom_prompts']) if settings['custom_prompts'] else {}
            classify_prompt = custom_prompts.get('classify', self.default_prompts['classify'])

            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            logger.info(f"AIè®¾ç½®è°ƒè¯• {cookie_id}: base_url={settings['base_url']}, model={settings['model_name']}")

            messages = [
                {"role": "system", "content": classify_prompt},
                {"role": "user", "content": message}
            ]

            # æ ¹æ®APIç±»å‹é€‰æ‹©è°ƒç”¨æ–¹å¼
            if self._is_dashscope_api(settings):
                logger.info(f"ä½¿ç”¨DashScope APIè¿›è¡Œæ„å›¾æ£€æµ‹")
                # DashScope æš‚æ—¶ä¿æŒè¾ƒå° Tokenï¼Œå¦‚æœæœ‰é—®é¢˜ä¹Ÿéœ€è¦è°ƒå¤§
                response_text = self._call_dashscope_api(settings, messages, max_tokens=100, temperature=0.1)
            else:
                logger.info(f"ä½¿ç”¨OpenAIå…¼å®¹APIè¿›è¡Œæ„å›¾æ£€æµ‹")
                client = self.get_client(cookie_id)
                if not client:
                    return 'default'
                
                # ä»ç„¶ä¿æŒè¾ƒå¤§çš„ token ä»¥é˜²å‚æ•°æ³¨å…¥å¤±è´¥ï¼Œç¡®ä¿ç¨³å®šæ€§
                response_text = self._call_openai_api(client, settings, messages, max_tokens=1000, temperature=0.1)

            intent = response_text.lower()
            # ç®€å•æ¸…æ´—å¯èƒ½å­˜åœ¨çš„æ ‡ç‚¹
            intent = intent.replace('.', '').replace('ã€‚', '').strip()
            
            if 'price' in intent or 'ä»·æ ¼' in intent:
                return 'price'
            elif 'tech' in intent or 'æŠ€æœ¯' in intent:
                return 'tech'
            else:
                # å…œåº•é€»è¾‘ï¼šå¦‚æœAIåºŸè¯å¤ªå¤šæ²¡è¿”å›æ ‡å‡†å…³é”®è¯ï¼Œä½†åŒ…å«äº†ç›¸å…³å­—çœ¼
                if 'default' in intent or 'å…¶ä»–' in intent:
                    return 'default'
                return 'default'

        except Exception as e:
            logger.error(f"æ„å›¾æ£€æµ‹å¤±è´¥ {cookie_id}: {e}")
            return 'default'
    
    def generate_reply(self, message: str, item_info: dict, chat_id: str,
                      cookie_id: str, user_id: str, item_id: str) -> Optional[str]:
        """ç”ŸæˆAIå›å¤"""
        if not self.is_ai_enabled(cookie_id):
            return None
        
        try:
            # 1. è·å–AIå›å¤è®¾ç½®
            settings = db_manager.get_ai_reply_settings(cookie_id)

            # 2. æ£€æµ‹æ„å›¾
            intent = self.detect_intent(message, cookie_id)
            logger.info(f"æ£€æµ‹åˆ°æ„å›¾: {intent} (è´¦å·: {cookie_id})")

            # 3. è·å–å¯¹è¯å†å²
            context = self.get_conversation_context(chat_id, cookie_id)

            # 4. è·å–è®®ä»·æ¬¡æ•°
            bargain_count = self.get_bargain_count(chat_id, cookie_id)

            # 5. æ£€æŸ¥è®®ä»·è½®æ•°é™åˆ¶
            if intent == "price":
                max_bargain_rounds = settings.get('max_bargain_rounds', 3)
                if bargain_count >= max_bargain_rounds:
                    logger.info(f"è®®ä»·æ¬¡æ•°å·²è¾¾ä¸Šé™ ({bargain_count}/{max_bargain_rounds})ï¼Œæ‹’ç»ç»§ç»­è®®ä»·")
                    # è¿”å›æ‹’ç»è®®ä»·çš„å›å¤
                    refuse_reply = f"æŠ±æ­‰ï¼Œè¿™ä¸ªä»·æ ¼å·²ç»æ˜¯æœ€ä¼˜æƒ çš„äº†ï¼Œä¸èƒ½å†ä¾¿å®œäº†å“¦ï¼"
                    # ä¿å­˜å¯¹è¯è®°å½•
                    self.save_conversation(chat_id, cookie_id, user_id, item_id, "user", message, intent)
                    self.save_conversation(chat_id, cookie_id, user_id, item_id, "assistant", refuse_reply, intent)
                    return refuse_reply

            # 6. æ„å»ºæç¤ºè¯
            custom_prompts = json.loads(settings['custom_prompts']) if settings['custom_prompts'] else {}
            system_prompt = custom_prompts.get(intent, self.default_prompts[intent])

            # 7. æ„å»ºå•†å“ä¿¡æ¯
            item_desc = f"å•†å“æ ‡é¢˜: {item_info.get('title', 'æœªçŸ¥')}\n"
            item_desc += f"å•†å“ä»·æ ¼: {item_info.get('price', 'æœªçŸ¥')}å…ƒ\n"
            item_desc += f"å•†å“æè¿°: {item_info.get('desc', 'æ— ')}"

            # 8. æ„å»ºå¯¹è¯å†å²
            context_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in context[-10:]])  # æœ€è¿‘10æ¡

            # 9. æ„å»ºç”¨æˆ·æ¶ˆæ¯
            max_bargain_rounds = settings.get('max_bargain_rounds', 3)
            max_discount_percent = settings.get('max_discount_percent', 10)
            max_discount_amount = settings.get('max_discount_amount', 100)

            user_prompt = f"""å•†å“ä¿¡æ¯ï¼š
{item_desc}

å¯¹è¯å†å²ï¼š
{context_str}

è®®ä»·è®¾ç½®ï¼š
- å½“å‰è®®ä»·æ¬¡æ•°ï¼š{bargain_count}
- æœ€å¤§è®®ä»·è½®æ•°ï¼š{max_bargain_rounds}
- æœ€å¤§ä¼˜æƒ ç™¾åˆ†æ¯”ï¼š{max_discount_percent}%
- æœ€å¤§ä¼˜æƒ é‡‘é¢ï¼š{max_discount_amount}å…ƒ

ç”¨æˆ·æ¶ˆæ¯ï¼š{message}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆå›å¤ï¼š"""

            # 10. è°ƒç”¨AIç”Ÿæˆå›å¤
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            # æ ¹æ®APIç±»å‹é€‰æ‹©è°ƒç”¨æ–¹å¼
            reply = ""
            if self._is_dashscope_api(settings):
                logger.info(f"ä½¿ç”¨DashScope APIç”Ÿæˆå›å¤")
                reply = self._call_dashscope_api(settings, messages, max_tokens=2000, temperature=0.7)
            else:
                logger.info(f"ä½¿ç”¨OpenAIå…¼å®¹APIç”Ÿæˆå›å¤")
                client = self.get_client(cookie_id)
                if not client:
                    return None
                # ã€é‡è¦ä¿®å¤ã€‘ç”Ÿæˆå›å¤æ—¶ Token ä¹Ÿè¦ç»™è¶³ï¼Œæ”¹ä¸º 2000
                reply = self._call_openai_api(client, settings, messages, max_tokens=2000, temperature=0.7)

            # æ£€æŸ¥å›å¤æ˜¯å¦ä¸ºç©º
            if not reply:
                logger.warning(f"AIå›å¤ç”Ÿæˆä¸ºç©º (è´¦å·: {cookie_id})")
                return None

            # 11. ä¿å­˜å¯¹è¯è®°å½•
            self.save_conversation(chat_id, cookie_id, user_id, item_id, "user", message, intent)
            self.save_conversation(chat_id, cookie_id, user_id, item_id, "assistant", reply, intent)

            # 12. æ›´æ–°è®®ä»·æ¬¡æ•°
            if intent == "price":
                self.increment_bargain_count(chat_id, cookie_id)
            
            logger.info(f"AIå›å¤ç”ŸæˆæˆåŠŸ (è´¦å·: {cookie_id}): {reply}")
            return reply
            
        except Exception as e:
            logger.error(f"AIå›å¤ç”Ÿæˆå¤±è´¥ {cookie_id}: {e}")
            return None
    
    def get_conversation_context(self, chat_id: str, cookie_id: str, limit: int = 20) -> List[Dict]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            with db_manager.lock:
                cursor = db_manager.conn.cursor()
                cursor.execute('''
                SELECT role, content FROM ai_conversations 
                WHERE chat_id = ? AND cookie_id = ? 
                ORDER BY created_at DESC LIMIT ?
                ''', (chat_id, cookie_id, limit))
                
                results = cursor.fetchall()
                # åè½¬é¡ºåºï¼Œä½¿å…¶æŒ‰æ—¶é—´æ­£åº
                context = [{"role": row[0], "content": row[1]} for row in reversed(results)]
                return context
        except Exception as e:
            logger.error(f"è·å–å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return []
    
    def save_conversation(self, chat_id: str, cookie_id: str, user_id: str, 
                         item_id: str, role: str, content: str, intent: str = None):
        """ä¿å­˜å¯¹è¯è®°å½•"""
        try:
            with db_manager.lock:
                cursor = db_manager.conn.cursor()
                cursor.execute('''
                INSERT INTO ai_conversations 
                (cookie_id, chat_id, user_id, item_id, role, content, intent)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (cookie_id, chat_id, user_id, item_id, role, content, intent))
                db_manager.conn.commit()
        except Exception as e:
            logger.error(f"ä¿å­˜å¯¹è¯è®°å½•å¤±è´¥: {e}")
    
    def get_bargain_count(self, chat_id: str, cookie_id: str) -> int:
        """è·å–è®®ä»·æ¬¡æ•°"""
        try:
            with db_manager.lock:
                cursor = db_manager.conn.cursor()
                cursor.execute('''
                SELECT COUNT(*) FROM ai_conversations 
                WHERE chat_id = ? AND cookie_id = ? AND intent = 'price' AND role = 'user'
                ''', (chat_id, cookie_id))
                
                result = cursor.fetchone()
                return result[0] if result else 0
        except Exception as e:
            logger.error(f"è·å–è®®ä»·æ¬¡æ•°å¤±è´¥: {e}")
            return 0
    
    def increment_bargain_count(self, chat_id: str, cookie_id: str):
        """å¢åŠ è®®ä»·æ¬¡æ•°ï¼ˆé€šè¿‡ä¿å­˜è®°å½•è‡ªåŠ¨å¢åŠ ï¼‰"""
        # è®®ä»·æ¬¡æ•°é€šè¿‡æŸ¥è¯¢priceæ„å›¾çš„ç”¨æˆ·æ¶ˆæ¯æ•°é‡æ¥è®¡ç®—ï¼Œæ— éœ€å•ç‹¬æ“ä½œ
        pass
    
    def clear_client_cache(self, cookie_id: str = None):
        """æ¸…ç†å®¢æˆ·ç«¯ç¼“å­˜"""
        if cookie_id:
            self.clients.pop(cookie_id, None)
            self.client_last_used.pop(cookie_id, None)
            logger.info(f"æ¸…ç†è´¦å· {cookie_id} çš„å®¢æˆ·ç«¯ç¼“å­˜")
        else:
            self.clients.clear()
            self.client_last_used.clear()
            logger.info("æ¸…ç†æ‰€æœ‰å®¢æˆ·ç«¯ç¼“å­˜")
    
    def cleanup_unused_clients(self, max_idle_hours: int = 24):
        """æ¸…ç†é•¿æ—¶é—´æœªä½¿ç”¨çš„å®¢æˆ·ç«¯ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        
        Args:
            max_idle_hours: æœ€å¤§ç©ºé—²æ—¶é—´ï¼ˆå°æ—¶ï¼‰ï¼Œé»˜è®¤24å°æ—¶
        """
        try:
            current_time = time.time()
            max_idle_seconds = max_idle_hours * 3600
            
            # æ‰¾å‡ºè¶…è¿‡æœ€å¤§ç©ºé—²æ—¶é—´çš„å®¢æˆ·ç«¯
            expired_clients = [
                cookie_id for cookie_id, last_used in self.client_last_used.items()
                if current_time - last_used > max_idle_seconds
            ]
            
            # æ¸…ç†è¿‡æœŸå®¢æˆ·ç«¯
            for cookie_id in expired_clients:
                self.clients.pop(cookie_id, None)
                self.client_last_used.pop(cookie_id, None)
                self.agents.pop(cookie_id, None)
            
            if expired_clients:
                logger.info(f"AIå›å¤å¼•æ“ï¼šæ¸…ç†äº† {len(expired_clients)} ä¸ªé•¿æ—¶é—´æœªä½¿ç”¨çš„å®¢æˆ·ç«¯")
                logger.debug(f"æ¸…ç†çš„è´¦å·: {expired_clients}")
                logger.debug(f"å½“å‰æ´»è·ƒå®¢æˆ·ç«¯æ•°é‡: {len(self.clients)}")
            
        except Exception as e:
            logger.error(f"AIå›å¤å¼•æ“ï¼šæ¸…ç†æœªä½¿ç”¨å®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")


# å…¨å±€AIå›å¤å¼•æ“å®ä¾‹
ai_reply_engine = AIReplyEngine()